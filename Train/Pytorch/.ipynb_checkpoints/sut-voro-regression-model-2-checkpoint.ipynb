{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>type</th>\n",
       "      <th>1-neighbour type</th>\n",
       "      <th>1-neighbour x</th>\n",
       "      <th>1-neighbour y</th>\n",
       "      <th>1-neighbour z</th>\n",
       "      <th>2-neighbour type</th>\n",
       "      <th>2-neighbour x</th>\n",
       "      <th>...</th>\n",
       "      <th>19-neighbour y</th>\n",
       "      <th>19-neighbour z</th>\n",
       "      <th>20-neighbour type</th>\n",
       "      <th>20-neighbour x</th>\n",
       "      <th>20-neighbour y</th>\n",
       "      <th>20-neighbour z</th>\n",
       "      <th>3-faced</th>\n",
       "      <th>4-faced</th>\n",
       "      <th>5-faced</th>\n",
       "      <th>6-faced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0291</td>\n",
       "      <td>54.9202</td>\n",
       "      <td>24.4540</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>26.7424</td>\n",
       "      <td>53.8812</td>\n",
       "      <td>22.4257</td>\n",
       "      <td>1.60</td>\n",
       "      <td>23.7794</td>\n",
       "      <td>...</td>\n",
       "      <td>53.51380</td>\n",
       "      <td>19.9562</td>\n",
       "      <td>1.28</td>\n",
       "      <td>28.6902</td>\n",
       "      <td>53.0777</td>\n",
       "      <td>28.2413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.4982</td>\n",
       "      <td>36.7826</td>\n",
       "      <td>37.0707</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>44.2310</td>\n",
       "      <td>38.3539</td>\n",
       "      <td>35.8460</td>\n",
       "      <td>1.28</td>\n",
       "      <td>40.5901</td>\n",
       "      <td>...</td>\n",
       "      <td>34.84750</td>\n",
       "      <td>34.3374</td>\n",
       "      <td>1.60</td>\n",
       "      <td>43.7738</td>\n",
       "      <td>39.0042</td>\n",
       "      <td>33.2507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.3755</td>\n",
       "      <td>24.9085</td>\n",
       "      <td>17.9155</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>43.8712</td>\n",
       "      <td>22.7444</td>\n",
       "      <td>16.3405</td>\n",
       "      <td>1.28</td>\n",
       "      <td>41.8245</td>\n",
       "      <td>...</td>\n",
       "      <td>28.08540</td>\n",
       "      <td>17.0551</td>\n",
       "      <td>1.28</td>\n",
       "      <td>45.1087</td>\n",
       "      <td>20.5074</td>\n",
       "      <td>16.6933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.9179</td>\n",
       "      <td>13.2666</td>\n",
       "      <td>54.6982</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51.7705</td>\n",
       "      <td>14.4300</td>\n",
       "      <td>53.9390</td>\n",
       "      <td>1.28</td>\n",
       "      <td>52.5371</td>\n",
       "      <td>...</td>\n",
       "      <td>9.36614</td>\n",
       "      <td>55.7498</td>\n",
       "      <td>1.28</td>\n",
       "      <td>54.2731</td>\n",
       "      <td>17.6069</td>\n",
       "      <td>52.2377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.7815</td>\n",
       "      <td>28.6099</td>\n",
       "      <td>25.9021</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>31.8357</td>\n",
       "      <td>30.5916</td>\n",
       "      <td>25.3170</td>\n",
       "      <td>1.28</td>\n",
       "      <td>28.2009</td>\n",
       "      <td>...</td>\n",
       "      <td>30.12860</td>\n",
       "      <td>28.7109</td>\n",
       "      <td>1.28</td>\n",
       "      <td>34.4023</td>\n",
       "      <td>29.2311</td>\n",
       "      <td>28.4718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x        y        z  type  1-neighbour type  1-neighbour x  \\\n",
       "0  26.0291  54.9202  24.4540  1.28              1.28        26.7424   \n",
       "1  42.4982  36.7826  37.0707  1.60              1.28        44.2310   \n",
       "2  44.3755  24.9085  17.9155  1.60              1.28        43.8712   \n",
       "3  53.9179  13.2666  54.6982  1.28              1.28        51.7705   \n",
       "4  30.7815  28.6099  25.9021  1.28              1.28        31.8357   \n",
       "\n",
       "   1-neighbour y  1-neighbour z  2-neighbour type  2-neighbour x  ...  \\\n",
       "0        53.8812        22.4257              1.60        23.7794  ...   \n",
       "1        38.3539        35.8460              1.28        40.5901  ...   \n",
       "2        22.7444        16.3405              1.28        41.8245  ...   \n",
       "3        14.4300        53.9390              1.28        52.5371  ...   \n",
       "4        30.5916        25.3170              1.28        28.2009  ...   \n",
       "\n",
       "   19-neighbour y  19-neighbour z  20-neighbour type  20-neighbour x  \\\n",
       "0        53.51380         19.9562               1.28         28.6902   \n",
       "1        34.84750         34.3374               1.60         43.7738   \n",
       "2        28.08540         17.0551               1.28         45.1087   \n",
       "3         9.36614         55.7498               1.28         54.2731   \n",
       "4        30.12860         28.7109               1.28         34.4023   \n",
       "\n",
       "   20-neighbour y  20-neighbour z  3-faced  4-faced  5-faced  6-faced  \n",
       "0         53.0777         28.2413      0.0      1.0      3.0      4.0  \n",
       "1         39.0042         33.2507      0.0      0.0      1.0     10.0  \n",
       "2         20.5074         16.6933      0.0      1.0      1.0      9.0  \n",
       "3         17.6069         52.2377      0.0      1.0      3.0      3.0  \n",
       "4         29.2311         28.4718      0.0      0.0      0.0     12.0  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../Output/output_1.csv')\n",
    "# df = pd.concat([\n",
    "#     pd.read_csv(F'../../Output/output_{i}.csv').drop(columns=[x for x in df.columns if 'id' in x]) \n",
    "#     for i in range(1, 12)])\n",
    "\n",
    "df = df.drop(\"id\", axis='columns')\n",
    "df = df.drop(\"nb\", axis='columns')\n",
    "df = df.drop(\"1-faced\", axis='columns')\n",
    "df = df.drop(\"2-faced\", axis='columns')\n",
    "df = df.drop(\"7-faced\", axis='columns')\n",
    "df = df.drop(\"8-faced\", axis='columns')\n",
    "df = df.drop(\"9-faced\", axis='columns')\n",
    "df = df.drop(\"10-faced\", axis='columns')\n",
    "df = df.drop(\"11-faced\", axis='columns')\n",
    "df = df.drop(\"12-faced\", axis='columns')\n",
    "df = df.drop(\"13-faced\", axis='columns')\n",
    "df = df.drop(\"1-neighbour id\", axis='columns')\n",
    "df = df.drop(\"2-neighbour id\", axis='columns')\n",
    "df = df.drop(\"3-neighbour id\", axis='columns')\n",
    "df = df.drop(\"4-neighbour id\", axis='columns')\n",
    "df = df.drop(\"5-neighbour id\", axis='columns')\n",
    "df = df.drop(\"6-neighbour id\", axis='columns')\n",
    "df = df.drop(\"7-neighbour id\", axis='columns')\n",
    "df = df.drop(\"8-neighbour id\", axis='columns')\n",
    "df = df.drop(\"9-neighbour id\", axis='columns')\n",
    "df = df.drop(\"10-neighbour id\", axis='columns')\n",
    "df = df.drop(\"11-neighbour id\", axis='columns')\n",
    "df = df.drop(\"12-neighbour id\", axis='columns')\n",
    "df = df.drop(\"13-neighbour id\", axis='columns')\n",
    "df = df.drop(\"14-neighbour id\", axis='columns')\n",
    "df = df.drop(\"15-neighbour id\", axis='columns')\n",
    "df = df.drop(\"16-neighbour id\", axis='columns')\n",
    "df = df.drop(\"17-neighbour id\", axis='columns')\n",
    "df = df.drop(\"18-neighbour id\", axis='columns')\n",
    "df = df.drop(\"19-neighbour id\", axis='columns')\n",
    "df = df.drop(\"20-neighbour id\", axis='columns')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>1-neighbour type</th>\n",
       "      <th>1-neighbour x</th>\n",
       "      <th>1-neighbour y</th>\n",
       "      <th>1-neighbour z</th>\n",
       "      <th>2-neighbour type</th>\n",
       "      <th>2-neighbour x</th>\n",
       "      <th>2-neighbour y</th>\n",
       "      <th>2-neighbour z</th>\n",
       "      <th>3-neighbour type</th>\n",
       "      <th>...</th>\n",
       "      <th>19-neighbour y</th>\n",
       "      <th>19-neighbour z</th>\n",
       "      <th>20-neighbour type</th>\n",
       "      <th>20-neighbour x</th>\n",
       "      <th>20-neighbour y</th>\n",
       "      <th>20-neighbour z</th>\n",
       "      <th>3-faced</th>\n",
       "      <th>4-faced</th>\n",
       "      <th>5-faced</th>\n",
       "      <th>6-faced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.576836</td>\n",
       "      <td>0.388080</td>\n",
       "      <td>0.281513</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.257664</td>\n",
       "      <td>0.478402</td>\n",
       "      <td>0.644893</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348504</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.786651</td>\n",
       "      <td>0.301527</td>\n",
       "      <td>0.907965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.713446</td>\n",
       "      <td>0.693553</td>\n",
       "      <td>0.349141</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.264960</td>\n",
       "      <td>0.246101</td>\n",
       "      <td>0.495553</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261634</td>\n",
       "      <td>0.163312</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.657128</td>\n",
       "      <td>0.773657</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.442708</td>\n",
       "      <td>0.254141</td>\n",
       "      <td>0.321067</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.210186</td>\n",
       "      <td>0.468088</td>\n",
       "      <td>0.638374</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860921</td>\n",
       "      <td>0.402252</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.583297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.252626</td>\n",
       "      <td>0.634020</td>\n",
       "      <td>0.412543</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.340936</td>\n",
       "      <td>0.393719</td>\n",
       "      <td>0.274168</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.621141</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.540918</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.216558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.620260</td>\n",
       "      <td>0.726067</td>\n",
       "      <td>0.433253</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.205613</td>\n",
       "      <td>0.486858</td>\n",
       "      <td>0.503263</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673249</td>\n",
       "      <td>0.820420</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.913050</td>\n",
       "      <td>0.570865</td>\n",
       "      <td>0.793144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  1-neighbour type  1-neighbour x  1-neighbour y  1-neighbour z  \\\n",
       "0  1.28              1.28       0.576836       0.388080       0.281513   \n",
       "1  1.60              1.28       0.713446       0.693553       0.349141   \n",
       "2  1.60              1.28       0.442708       0.254141       0.321067   \n",
       "3  1.28              1.28       0.252626       0.634020       0.412543   \n",
       "4  1.28              1.28       0.620260       0.726067       0.433253   \n",
       "\n",
       "   2-neighbour type  2-neighbour x  2-neighbour y  2-neighbour z  \\\n",
       "0              1.60       0.257664       0.478402       0.644893   \n",
       "1              1.28       0.264960       0.246101       0.495553   \n",
       "2              1.28       0.210186       0.468088       0.638374   \n",
       "3              1.28       0.340936       0.393719       0.274168   \n",
       "4              1.28       0.205613       0.486858       0.503263   \n",
       "\n",
       "   3-neighbour type  ...  19-neighbour y  19-neighbour z  20-neighbour type  \\\n",
       "0              1.28  ...        0.348504        0.015501               1.28   \n",
       "1              1.28  ...        0.261634        0.163312               1.60   \n",
       "2              1.28  ...        0.860921        0.402252               1.28   \n",
       "3              1.28  ...        0.050680        0.621141               1.28   \n",
       "4              1.28  ...        0.673249        0.820420               1.28   \n",
       "\n",
       "   20-neighbour x  20-neighbour y  20-neighbour z  3-faced  4-faced  5-faced  \\\n",
       "0        0.786651        0.301527        0.907965      0.0      1.0      3.0   \n",
       "1        0.657128        0.773657        0.029452      0.0      0.0      1.0   \n",
       "2        0.583297        0.000000        0.361148      0.0      1.0      1.0   \n",
       "3        0.540918        0.999988        0.216558      0.0      1.0      3.0   \n",
       "4        0.913050        0.570865        0.793144      0.0      0.0      0.0   \n",
       "\n",
       "   6-faced  \n",
       "0      4.0  \n",
       "1     10.0  \n",
       "2      9.0  \n",
       "3      3.0  \n",
       "4     12.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizing(row):\n",
    "    x, y, z = row.iloc[:3]\n",
    "\n",
    "    for i in row.keys():\n",
    "        if i[-1] == \"x\":\n",
    "            row[i] = row[i] - x\n",
    "        elif i[-1] == \"y\":\n",
    "            row[i] = row[i] - y\n",
    "        elif i[-1] == \"z\":\n",
    "            row[i] = row[i] - z\n",
    "\n",
    "    maximum = -1\n",
    "    for i in row.keys():\n",
    "        if i[-1] in [\"x\", \"y\", \"z\"]:\n",
    "            if abs(row[i]) > maximum:\n",
    "                maximum = abs(row[i])\n",
    "\n",
    "\n",
    "    for i in row.keys():\n",
    "        if i[-1] in [\"x\", \"y\", \"z\"]:\n",
    "            row[i] = (row[i] / (maximum*2)) + 0.5\n",
    "    return row\n",
    "\n",
    "\n",
    "normalized_df = []\n",
    "for row in df.iterrows():\n",
    "    normalized_df.append(normalizing(row[1]))\n",
    "normalized_df = pd.DataFrame(normalized_df)\n",
    "normalized_df.drop([\"x\",\"y\",\"z\"], axis=1, inplace = True)\n",
    "\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13500, 85)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalized_df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()\n",
    "data = data.astype(np.float32)\n",
    "\n",
    "inp_data_train, inp_data_test, out_data_train, out_data_test = train_test_split(\n",
    "    data[:, :-4], data[:, -4:], test_size=0.2, random_state=123)\n",
    "\n",
    "inp_data_test, inp_data_valid, out_data_test, out_data_valid = train_test_split(\n",
    "    inp_data_test, out_data_test, test_size=0.5, random_state=123)\n",
    "\n",
    "inp_data_test , out_data_test  = \\\n",
    "    torch.from_numpy(inp_data_test) , torch.from_numpy(out_data_test)\n",
    "\n",
    "inp_data_train, out_data_train = \\\n",
    "    torch.from_numpy(inp_data_train), torch.from_numpy(out_data_train)\n",
    "\n",
    "inp_data_valid, out_data_valid = \\\n",
    "    torch.from_numpy(inp_data_valid), torch.from_numpy(out_data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(inp_data_train, out_data_train)\n",
    "valid_dataset = TensorDataset(inp_data_valid, out_data_valid)\n",
    "test_dataset  = TensorDataset(inp_data_test , out_data_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # todo: more stable updating model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset , batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nf\n",
    "\n",
    "class RegressionMultiout(nn.Module):\n",
    "    def __init__(self, inputs_size, hidden_size, output_size):\n",
    "        super(RegressionMultiout, self).__init__()\n",
    "        \n",
    "        self.vorono = nn.Sequential(\n",
    "            nn.Linear(inputs_size, 32),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(8, output_size),\n",
    "        )\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \n",
    "        def inner_init_weights(layer):\n",
    "            if not isinstance(layer, nn.Linear):\n",
    "                return\n",
    "            \n",
    "            nn.init.xavier_uniform_(layer.weight.data)\n",
    "            nn.init.constant_(layer.bias.data, 0.1)\n",
    "            \n",
    "        self.vorono.apply(inner_init_weights)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vorono(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: change HIDDEN_SIZE for more complex model. (less overfit and loss. more epoch is needed!)\n",
    "INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE = inp_data_train.shape[1], 35, out_data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionMultiout(\n",
       "  (vorono): Sequential(\n",
       "    (0): Linear(in_features=81, out_features=32, bias=True)\n",
       "    (1): Dropout(p=0.4, inplace=False)\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "    (6): LeakyReLU(negative_slope=0.01)\n",
       "    (7): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): Linear(in_features=8, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionMultiout(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW, Adam, SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size_train = len(train_loader)\n",
    "batch_size_valid = len(valid_loader)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.005)\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005.running_loss: 1.87100\n",
      "010.running_loss: 1.84234\n",
      "015.running_loss: 1.84617\n",
      "020.running_loss: 1.82536\n",
      "025.running_loss: 1.79968\n",
      "030.running_loss: 1.82008\n",
      "035.running_loss: 1.79127\n",
      "040.running_loss: 1.79540\n",
      "045.running_loss: 1.78048\n",
      "050.running_loss: 1.76441\n",
      "055.running_loss: 1.80029\n",
      "060.running_loss: 1.77653\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [151]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inp_train, out_train \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     12\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model(inp_train)\n\u001b[1;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\nn\\functional.py:3280\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3279\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m-> 3280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    for inp_train, out_train in train_loader:\n",
    "        \n",
    "        prediction = model(inp_train)\n",
    "        loss = criterion(prediction, out_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        test_loss = 0\n",
    "        for inp_valid, out_valid in valid_loader:\n",
    "        \n",
    "            prediction = model(inp_valid)\n",
    "            loss = criterion(prediction, out_valid)\n",
    "            test_loss += loss.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    running_loss /= batch_size_train\n",
    "    train_loss.append(running_loss)\n",
    "        \n",
    "    test_loss /= batch_size_valid\n",
    "    validation_loss.append(test_loss)\n",
    "    \n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "#         print('%03d.learning_rate: %.05f' % (epoch, optimizer.param_groups[0][\"lr\"]))\n",
    "        print('%03d.running_loss: %.05f' % (epoch, running_loss))\n",
    "    \n",
    "plt.plot(range(1, num_epochs - 4), train_loss[5:], label='training loss')\n",
    "plt.plot(range(1, num_epochs - 4), validation_loss[5:], label='validation loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model(inp_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Prediction : [-0.  2.  3.  2.]\n",
      "Real output: [0. 0. 3. 6.]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, test_predictions.shape[0])\n",
    "print('Test-Prediction :', np.round(test_predictions[idx].detach().numpy(), 0))\n",
    "print('Real output:', out_data_test[idx].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model(inp_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : [-0.  0.  2.  8.]\n",
      "Real output: [0. 0. 2. 8.]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, train_predictions.shape[0])\n",
    "print('Prediction :', np.round(train_predictions[idx].detach().numpy(), 0))\n",
    "print('Real output:', out_data_train[idx].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save('sutovoro_torch_model_scripted.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
