{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>type</th>\n",
       "      <th>1-neighbour type</th>\n",
       "      <th>1-neighbour x</th>\n",
       "      <th>1-neighbour y</th>\n",
       "      <th>1-neighbour z</th>\n",
       "      <th>2-neighbour type</th>\n",
       "      <th>2-neighbour x</th>\n",
       "      <th>...</th>\n",
       "      <th>19-neighbour y</th>\n",
       "      <th>19-neighbour z</th>\n",
       "      <th>20-neighbour type</th>\n",
       "      <th>20-neighbour x</th>\n",
       "      <th>20-neighbour y</th>\n",
       "      <th>20-neighbour z</th>\n",
       "      <th>3-faced</th>\n",
       "      <th>4-faced</th>\n",
       "      <th>5-faced</th>\n",
       "      <th>6-faced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0291</td>\n",
       "      <td>54.9202</td>\n",
       "      <td>24.4540</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>26.7424</td>\n",
       "      <td>53.8812</td>\n",
       "      <td>22.4257</td>\n",
       "      <td>1.60</td>\n",
       "      <td>23.7794</td>\n",
       "      <td>...</td>\n",
       "      <td>53.51380</td>\n",
       "      <td>19.9562</td>\n",
       "      <td>1.28</td>\n",
       "      <td>28.6902</td>\n",
       "      <td>53.0777</td>\n",
       "      <td>28.2413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.4982</td>\n",
       "      <td>36.7826</td>\n",
       "      <td>37.0707</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>44.2310</td>\n",
       "      <td>38.3539</td>\n",
       "      <td>35.8460</td>\n",
       "      <td>1.28</td>\n",
       "      <td>40.5901</td>\n",
       "      <td>...</td>\n",
       "      <td>34.84750</td>\n",
       "      <td>34.3374</td>\n",
       "      <td>1.60</td>\n",
       "      <td>43.7738</td>\n",
       "      <td>39.0042</td>\n",
       "      <td>33.2507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.3755</td>\n",
       "      <td>24.9085</td>\n",
       "      <td>17.9155</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>43.8712</td>\n",
       "      <td>22.7444</td>\n",
       "      <td>16.3405</td>\n",
       "      <td>1.28</td>\n",
       "      <td>41.8245</td>\n",
       "      <td>...</td>\n",
       "      <td>28.08540</td>\n",
       "      <td>17.0551</td>\n",
       "      <td>1.28</td>\n",
       "      <td>45.1087</td>\n",
       "      <td>20.5074</td>\n",
       "      <td>16.6933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.9179</td>\n",
       "      <td>13.2666</td>\n",
       "      <td>54.6982</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51.7705</td>\n",
       "      <td>14.4300</td>\n",
       "      <td>53.9390</td>\n",
       "      <td>1.28</td>\n",
       "      <td>52.5371</td>\n",
       "      <td>...</td>\n",
       "      <td>9.36614</td>\n",
       "      <td>55.7498</td>\n",
       "      <td>1.28</td>\n",
       "      <td>54.2731</td>\n",
       "      <td>17.6069</td>\n",
       "      <td>52.2377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.7815</td>\n",
       "      <td>28.6099</td>\n",
       "      <td>25.9021</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>31.8357</td>\n",
       "      <td>30.5916</td>\n",
       "      <td>25.3170</td>\n",
       "      <td>1.28</td>\n",
       "      <td>28.2009</td>\n",
       "      <td>...</td>\n",
       "      <td>30.12860</td>\n",
       "      <td>28.7109</td>\n",
       "      <td>1.28</td>\n",
       "      <td>34.4023</td>\n",
       "      <td>29.2311</td>\n",
       "      <td>28.4718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x        y        z  type  1-neighbour type  1-neighbour x  \\\n",
       "0  26.0291  54.9202  24.4540  1.28              1.28        26.7424   \n",
       "1  42.4982  36.7826  37.0707  1.60              1.28        44.2310   \n",
       "2  44.3755  24.9085  17.9155  1.60              1.28        43.8712   \n",
       "3  53.9179  13.2666  54.6982  1.28              1.28        51.7705   \n",
       "4  30.7815  28.6099  25.9021  1.28              1.28        31.8357   \n",
       "\n",
       "   1-neighbour y  1-neighbour z  2-neighbour type  2-neighbour x  ...  \\\n",
       "0        53.8812        22.4257              1.60        23.7794  ...   \n",
       "1        38.3539        35.8460              1.28        40.5901  ...   \n",
       "2        22.7444        16.3405              1.28        41.8245  ...   \n",
       "3        14.4300        53.9390              1.28        52.5371  ...   \n",
       "4        30.5916        25.3170              1.28        28.2009  ...   \n",
       "\n",
       "   19-neighbour y  19-neighbour z  20-neighbour type  20-neighbour x  \\\n",
       "0        53.51380         19.9562               1.28         28.6902   \n",
       "1        34.84750         34.3374               1.60         43.7738   \n",
       "2        28.08540         17.0551               1.28         45.1087   \n",
       "3         9.36614         55.7498               1.28         54.2731   \n",
       "4        30.12860         28.7109               1.28         34.4023   \n",
       "\n",
       "   20-neighbour y  20-neighbour z  3-faced  4-faced  5-faced  6-faced  \n",
       "0         53.0777         28.2413      0.0      1.0      3.0      4.0  \n",
       "1         39.0042         33.2507      0.0      0.0      1.0     10.0  \n",
       "2         20.5074         16.6933      0.0      1.0      1.0      9.0  \n",
       "3         17.6069         52.2377      0.0      1.0      3.0      3.0  \n",
       "4         29.2311         28.4718      0.0      0.0      0.0     12.0  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../Output/output_1.csv')\n",
    "# df = pd.concat([\n",
    "#     pd.read_csv(F'../../Output/output_{i}.csv').drop(columns=[x for x in df.columns if 'id' in x]) \n",
    "#     for i in range(1, 12)])\n",
    "\n",
    "df = df.drop(\"id\", axis='columns')\n",
    "df = df.drop(\"nb\", axis='columns')\n",
    "df = df.drop(\"1-faced\", axis='columns')\n",
    "df = df.drop(\"2-faced\", axis='columns')\n",
    "df = df.drop(\"7-faced\", axis='columns')\n",
    "df = df.drop(\"8-faced\", axis='columns')\n",
    "df = df.drop(\"9-faced\", axis='columns')\n",
    "df = df.drop(\"10-faced\", axis='columns')\n",
    "df = df.drop(\"11-faced\", axis='columns')\n",
    "df = df.drop(\"12-faced\", axis='columns')\n",
    "df = df.drop(\"13-faced\", axis='columns')\n",
    "df = df.drop(\"1-neighbour id\", axis='columns')\n",
    "df = df.drop(\"2-neighbour id\", axis='columns')\n",
    "df = df.drop(\"3-neighbour id\", axis='columns')\n",
    "df = df.drop(\"4-neighbour id\", axis='columns')\n",
    "df = df.drop(\"5-neighbour id\", axis='columns')\n",
    "df = df.drop(\"6-neighbour id\", axis='columns')\n",
    "df = df.drop(\"7-neighbour id\", axis='columns')\n",
    "df = df.drop(\"8-neighbour id\", axis='columns')\n",
    "df = df.drop(\"9-neighbour id\", axis='columns')\n",
    "df = df.drop(\"10-neighbour id\", axis='columns')\n",
    "df = df.drop(\"11-neighbour id\", axis='columns')\n",
    "df = df.drop(\"12-neighbour id\", axis='columns')\n",
    "df = df.drop(\"13-neighbour id\", axis='columns')\n",
    "df = df.drop(\"14-neighbour id\", axis='columns')\n",
    "df = df.drop(\"15-neighbour id\", axis='columns')\n",
    "df = df.drop(\"16-neighbour id\", axis='columns')\n",
    "df = df.drop(\"17-neighbour id\", axis='columns')\n",
    "df = df.drop(\"18-neighbour id\", axis='columns')\n",
    "df = df.drop(\"19-neighbour id\", axis='columns')\n",
    "df = df.drop(\"20-neighbour id\", axis='columns')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>1-neighbour type</th>\n",
       "      <th>1-neighbour x</th>\n",
       "      <th>1-neighbour y</th>\n",
       "      <th>1-neighbour z</th>\n",
       "      <th>2-neighbour type</th>\n",
       "      <th>2-neighbour x</th>\n",
       "      <th>2-neighbour y</th>\n",
       "      <th>2-neighbour z</th>\n",
       "      <th>3-neighbour type</th>\n",
       "      <th>...</th>\n",
       "      <th>19-neighbour y</th>\n",
       "      <th>19-neighbour z</th>\n",
       "      <th>20-neighbour type</th>\n",
       "      <th>20-neighbour x</th>\n",
       "      <th>20-neighbour y</th>\n",
       "      <th>20-neighbour z</th>\n",
       "      <th>3-faced</th>\n",
       "      <th>4-faced</th>\n",
       "      <th>5-faced</th>\n",
       "      <th>6-faced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.576836</td>\n",
       "      <td>0.388080</td>\n",
       "      <td>0.281513</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.257664</td>\n",
       "      <td>0.478402</td>\n",
       "      <td>0.644893</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348504</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.786651</td>\n",
       "      <td>0.301527</td>\n",
       "      <td>0.907965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.713446</td>\n",
       "      <td>0.693553</td>\n",
       "      <td>0.349141</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.264960</td>\n",
       "      <td>0.246101</td>\n",
       "      <td>0.495553</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261634</td>\n",
       "      <td>0.163312</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.657128</td>\n",
       "      <td>0.773657</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.442708</td>\n",
       "      <td>0.254141</td>\n",
       "      <td>0.321067</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.210186</td>\n",
       "      <td>0.468088</td>\n",
       "      <td>0.638374</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860921</td>\n",
       "      <td>0.402252</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.583297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.252626</td>\n",
       "      <td>0.634020</td>\n",
       "      <td>0.412543</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.340936</td>\n",
       "      <td>0.393719</td>\n",
       "      <td>0.274168</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.621141</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.540918</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.216558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.620260</td>\n",
       "      <td>0.726067</td>\n",
       "      <td>0.433253</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.205613</td>\n",
       "      <td>0.486858</td>\n",
       "      <td>0.503263</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673249</td>\n",
       "      <td>0.820420</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.913050</td>\n",
       "      <td>0.570865</td>\n",
       "      <td>0.793144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  1-neighbour type  1-neighbour x  1-neighbour y  1-neighbour z  \\\n",
       "0  1.28              1.28       0.576836       0.388080       0.281513   \n",
       "1  1.60              1.28       0.713446       0.693553       0.349141   \n",
       "2  1.60              1.28       0.442708       0.254141       0.321067   \n",
       "3  1.28              1.28       0.252626       0.634020       0.412543   \n",
       "4  1.28              1.28       0.620260       0.726067       0.433253   \n",
       "\n",
       "   2-neighbour type  2-neighbour x  2-neighbour y  2-neighbour z  \\\n",
       "0              1.60       0.257664       0.478402       0.644893   \n",
       "1              1.28       0.264960       0.246101       0.495553   \n",
       "2              1.28       0.210186       0.468088       0.638374   \n",
       "3              1.28       0.340936       0.393719       0.274168   \n",
       "4              1.28       0.205613       0.486858       0.503263   \n",
       "\n",
       "   3-neighbour type  ...  19-neighbour y  19-neighbour z  20-neighbour type  \\\n",
       "0              1.28  ...        0.348504        0.015501               1.28   \n",
       "1              1.28  ...        0.261634        0.163312               1.60   \n",
       "2              1.28  ...        0.860921        0.402252               1.28   \n",
       "3              1.28  ...        0.050680        0.621141               1.28   \n",
       "4              1.28  ...        0.673249        0.820420               1.28   \n",
       "\n",
       "   20-neighbour x  20-neighbour y  20-neighbour z  3-faced  4-faced  5-faced  \\\n",
       "0        0.786651        0.301527        0.907965      0.0      1.0      3.0   \n",
       "1        0.657128        0.773657        0.029452      0.0      0.0      1.0   \n",
       "2        0.583297        0.000000        0.361148      0.0      1.0      1.0   \n",
       "3        0.540918        0.999988        0.216558      0.0      1.0      3.0   \n",
       "4        0.913050        0.570865        0.793144      0.0      0.0      0.0   \n",
       "\n",
       "   6-faced  \n",
       "0      4.0  \n",
       "1     10.0  \n",
       "2      9.0  \n",
       "3      3.0  \n",
       "4     12.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizing(row):\n",
    "    x, y, z = row.iloc[:3]\n",
    "\n",
    "    for i in row.keys():\n",
    "        if i[-1] == \"x\":\n",
    "            row[i] = row[i] - x\n",
    "        elif i[-1] == \"y\":\n",
    "            row[i] = row[i] - y\n",
    "        elif i[-1] == \"z\":\n",
    "            row[i] = row[i] - z\n",
    "\n",
    "    maximum = -1\n",
    "    for i in row.keys():\n",
    "        if i[-1] in [\"x\", \"y\", \"z\"]:\n",
    "            if abs(row[i]) > maximum:\n",
    "                maximum = abs(row[i])\n",
    "\n",
    "\n",
    "    for i in row.keys():\n",
    "        if i[-1] in [\"x\", \"y\", \"z\"]:\n",
    "            row[i] = (row[i] / (maximum*2)) + 0.5\n",
    "    return row\n",
    "\n",
    "\n",
    "normalized_df = []\n",
    "for row in df.iterrows():\n",
    "    normalized_df.append(normalizing(row[1]))\n",
    "normalized_df = pd.DataFrame(normalized_df)\n",
    "normalized_df.drop([\"x\",\"y\",\"z\"], axis=1, inplace = True)\n",
    "\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13500, 85)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalized_df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()\n",
    "data = data.astype(np.float32)\n",
    "\n",
    "inp_data_train, inp_data_test, out_data_train, out_data_test = train_test_split(\n",
    "    data[:, :-4], data[:, -4:], test_size=0.2, random_state=123)\n",
    "\n",
    "inp_data_test, inp_data_valid, out_data_test, out_data_valid = train_test_split(\n",
    "    inp_data_test, out_data_test, test_size=0.5, random_state=123)\n",
    "\n",
    "inp_data_test , out_data_test  = \\\n",
    "    torch.from_numpy(inp_data_test) , torch.from_numpy(out_data_test)\n",
    "\n",
    "inp_data_train, out_data_train = \\\n",
    "    torch.from_numpy(inp_data_train), torch.from_numpy(out_data_train)\n",
    "\n",
    "inp_data_valid, out_data_valid = \\\n",
    "    torch.from_numpy(inp_data_valid), torch.from_numpy(out_data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(inp_data_train, out_data_train)\n",
    "valid_dataset = TensorDataset(inp_data_valid, out_data_valid)\n",
    "test_dataset  = TensorDataset(inp_data_test , out_data_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100 # todo: more stable updating model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset , batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nf\n",
    "\n",
    "class RegressionMultiout(nn.Module):\n",
    "    def __init__(self, inputs_size, output_size):\n",
    "        super(RegressionMultiout, self).__init__()\n",
    "        \n",
    "        self.vorono = nn.Sequential(\n",
    "            nn.Linear(inputs_size, 32),\n",
    "#             nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(8, output_size),\n",
    "        )\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \n",
    "        def inner_init_weights(layer):\n",
    "            if not isinstance(layer, nn.Linear):\n",
    "                return\n",
    "            \n",
    "            nn.init.xavier_uniform_(layer.weight.data)\n",
    "            nn.init.constant_(layer.bias.data, 0.1)\n",
    "            \n",
    "        self.vorono.apply(inner_init_weights)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vorono(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE, OUTPUT_SIZE = inp_data_train.shape[1], out_data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionMultiout(\n",
       "  (vorono): Sequential(\n",
       "    (0): Linear(in_features=81, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=32, out_features=8, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Linear(in_features=8, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionMultiout(INPUT_SIZE, OUTPUT_SIZE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW, Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size_train = len(train_loader)\n",
    "batch_size_valid = len(valid_loader)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=5e-3)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005.running_loss: 1.75263\n",
      "010.running_loss: 1.58416\n",
      "015.running_loss: 1.47662\n",
      "020.running_loss: 1.41340\n",
      "025.running_loss: 1.36331\n",
      "030.running_loss: 1.33058\n",
      "035.running_loss: 1.29544\n",
      "040.running_loss: 1.27621\n",
      "045.running_loss: 1.25164\n",
      "050.running_loss: 1.23688\n",
      "055.running_loss: 1.21764\n",
      "060.running_loss: 1.20749\n",
      "065.running_loss: 1.19212\n",
      "070.running_loss: 1.18622\n",
      "075.running_loss: 1.17376\n",
      "080.running_loss: 1.16904\n",
      "085.running_loss: 1.15736\n",
      "090.running_loss: 1.15272\n",
      "095.running_loss: 1.14415\n",
      "100.running_loss: 1.14037\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    for inp_train, out_train in train_loader:\n",
    "        \n",
    "        prediction = model(inp_train)\n",
    "        loss = criterion(prediction, out_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        test_loss = 0\n",
    "        for inp_valid, out_valid in valid_loader:\n",
    "        \n",
    "            prediction = model(inp_valid)\n",
    "            loss = criterion(prediction, out_valid)\n",
    "            test_loss += loss.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    running_loss /= batch_size_train\n",
    "    train_loss.append(running_loss)\n",
    "        \n",
    "    test_loss /= batch_size_valid\n",
    "    validation_loss.append(test_loss)\n",
    "    \n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "#         print('%03d.learning_rate: %.05f' % (epoch, optimizer.param_groups[0][\"lr\"]))\n",
    "        print('%03d.running_loss: %.05f' % (epoch, running_loss))\n",
    "    \n",
    "plt.plot(range(1, num_epochs - 4), train_loss[5:], label='training loss')\n",
    "plt.plot(range(1, num_epochs - 4), validation_loss[5:], label='validation loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model(inp_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Prediction : [-0.  2.  3.  2.]\n",
      "Real output: [0. 0. 3. 6.]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, test_predictions.shape[0])\n",
    "print('Test-Prediction :', np.round(test_predictions[idx].detach().numpy(), 0))\n",
    "print('Real output:', out_data_test[idx].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model(inp_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : [-0.  0.  2.  8.]\n",
      "Real output: [0. 0. 2. 8.]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, train_predictions.shape[0])\n",
    "print('Prediction :', np.round(train_predictions[idx].detach().numpy(), 0))\n",
    "print('Real output:', out_data_train[idx].detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
