{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a8c13d",
   "metadata": {
    "id": "90a8c13d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from matplotlib import image as mat_image\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d08057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing(row):\n",
    "    x, y, z = row.iloc[:3]\n",
    "\n",
    "    for i in row.keys():\n",
    "        if i[-1] == \"x\":\n",
    "            row[i] = row[i] - x\n",
    "        elif i[-1] == \"y\":\n",
    "            row[i] = row[i] - y\n",
    "        elif i[-1] == \"z\":\n",
    "            row[i] = row[i] - z\n",
    "\n",
    "    maximum = -1\n",
    "    for i in row.keys():\n",
    "        if i[-1] in [\"x\", \"y\", \"z\"]:\n",
    "            if abs(row[i]) > maximum:\n",
    "                maximum = abs(row[i])\n",
    "\n",
    "\n",
    "    for i in row.keys():\n",
    "        if i[-1] in [\"x\", \"y\", \"z\"]:\n",
    "            row[i] = (row[i] / (maximum*2)) + 0.5\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6c9d9b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "b6c9d9b2",
    "outputId": "d8ae4abe-aef6-4765-8479-b8ca077db016"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radious</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>id0</th>\n",
       "      <th>r0</th>\n",
       "      <th>d0</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>...</th>\n",
       "      <th>y18</th>\n",
       "      <th>z18</th>\n",
       "      <th>id19</th>\n",
       "      <th>r19</th>\n",
       "      <th>d19</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>voro</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>26.0547</td>\n",
       "      <td>54.8945</td>\n",
       "      <td>24.4226</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.341781</td>\n",
       "      <td>26.7448</td>\n",
       "      <td>53.8702</td>\n",
       "      <td>...</td>\n",
       "      <td>53.50000</td>\n",
       "      <td>19.9368</td>\n",
       "      <td>5137.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>5.014430</td>\n",
       "      <td>28.7188</td>\n",
       "      <td>53.0350</td>\n",
       "      <td>28.2422</td>\n",
       "      <td>1 4 2 5 1</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>42.4972</td>\n",
       "      <td>36.7715</td>\n",
       "      <td>37.0493</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.603926</td>\n",
       "      <td>44.1997</td>\n",
       "      <td>38.3357</td>\n",
       "      <td>...</td>\n",
       "      <td>34.83190</td>\n",
       "      <td>34.3353</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.595823</td>\n",
       "      <td>43.7817</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>33.2407</td>\n",
       "      <td>0 1 10 4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>44.3695</td>\n",
       "      <td>24.9178</td>\n",
       "      <td>17.8966</td>\n",
       "      <td>8071.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.710196</td>\n",
       "      <td>43.8979</td>\n",
       "      <td>22.7395</td>\n",
       "      <td>...</td>\n",
       "      <td>28.06890</td>\n",
       "      <td>17.0522</td>\n",
       "      <td>13268.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.641378</td>\n",
       "      <td>45.1336</td>\n",
       "      <td>20.5008</td>\n",
       "      <td>16.6930</td>\n",
       "      <td>0 0 12 6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>53.9043</td>\n",
       "      <td>13.2733</td>\n",
       "      <td>54.6890</td>\n",
       "      <td>13237.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.543381</td>\n",
       "      <td>51.7689</td>\n",
       "      <td>14.4322</td>\n",
       "      <td>...</td>\n",
       "      <td>9.36942</td>\n",
       "      <td>55.7248</td>\n",
       "      <td>3508.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>5.006968</td>\n",
       "      <td>54.2463</td>\n",
       "      <td>17.6213</td>\n",
       "      <td>52.2298</td>\n",
       "      <td>1 3 3 3</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>30.7741</td>\n",
       "      <td>28.6005</td>\n",
       "      <td>25.9002</td>\n",
       "      <td>10123.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.345455</td>\n",
       "      <td>31.8255</td>\n",
       "      <td>30.6149</td>\n",
       "      <td>...</td>\n",
       "      <td>30.12950</td>\n",
       "      <td>28.7256</td>\n",
       "      <td>5005.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.502687</td>\n",
       "      <td>34.6103</td>\n",
       "      <td>30.3115</td>\n",
       "      <td>24.2784</td>\n",
       "      <td>0 0 12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  radious        x        y        z      id0    r0        d0       x0  \\\n",
       "0  1.0     1.28  26.0547  54.8945  24.4226   1734.0  1.28  2.341781  26.7448   \n",
       "1  2.0     1.60  42.4972  36.7715  37.0493    955.0  1.28  2.603926  44.1997   \n",
       "2  3.0     1.60  44.3695  24.9178  17.8966   8071.0  1.28  2.710196  43.8979   \n",
       "3  4.0     1.28  53.9043  13.2733  54.6890  13237.0  1.28  2.543381  51.7689   \n",
       "4  5.0     1.28  30.7741  28.6005  25.9002  10123.0  1.28  2.345455  31.8255   \n",
       "\n",
       "        y0  ...       y18      z18     id19   r19       d19      x19      y19  \\\n",
       "0  53.8702  ...  53.50000  19.9368   5137.0  1.28  5.014430  28.7188  53.0350   \n",
       "1  38.3357  ...  34.83190  34.3353   2060.0  1.60  4.595823  43.7817  39.0000   \n",
       "2  22.7395  ...  28.06890  17.0522  13268.0  1.28  4.641378  45.1336  20.5008   \n",
       "3  14.4322  ...   9.36942  55.7248   3508.0  1.28  5.006968  54.2463  17.6213   \n",
       "4  30.6149  ...  30.12950  28.7256   5005.0  1.60  4.502687  34.6103  30.3115   \n",
       "\n",
       "       z19       voro  label  \n",
       "0  28.2422  1 4 2 5 1    304  \n",
       "1  33.2407   0 1 10 4      9  \n",
       "2  16.6930   0 0 12 6      5  \n",
       "3  52.2298    1 3 3 3    243  \n",
       "4  24.2784     0 0 12      0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../model_input_csv/Cu-Zr5111.txt.csv')\n",
    "# df = pd.concat([\n",
    "#     pd.read_csv(F'../../Output/output_{i}.csv').drop(columns=[x for x in df.columns if 'id' in x]) \n",
    "#     for i in range(1, 12)])\n",
    "\n",
    "df = df.drop(\"Unnamed: 0\", axis='columns')\n",
    "# df = df.drop(\"nb\", axis='columns')\n",
    "# df = df.drop(\"1-faced\", axis='columns')\n",
    "# df = df.drop(\"2-faced\", axis='columns')\n",
    "# df = df.drop(\"7-faced\", axis='columns')\n",
    "# df = df.drop(\"8-faced\", axis='columns')\n",
    "# df = df.drop(\"9-faced\", axis='columns')\n",
    "# df = df.drop(\"10-faced\", axis='columns')\n",
    "# df = df.drop(\"11-faced\", axis='columns')\n",
    "# df = df.drop(\"12-faced\", axis='columns')\n",
    "# df = df.drop(\"13-faced\", axis='columns')\n",
    "# df = df.drop(\"1-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"2-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"3-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"4-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"5-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"6-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"7-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"8-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"9-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"10-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"11-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"12-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"13-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"14-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"15-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"16-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"17-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"18-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"19-neighbour id\", axis='columns')\n",
    "# df = df.drop(\"20-neighbour id\", axis='columns')\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['label']= label_encoder.fit_transform(df['voro'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ff3c925",
   "metadata": {
    "id": "2ff3c925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25]\n",
      " [45]\n",
      " [43]\n",
      " ...\n",
      " [7]\n",
      " [302]\n",
      " [44]]\n"
     ]
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "\n",
    "inp_data_train, inp_data_test, out_data_train, out_data_test = train_test_split(\n",
    "    data[:, :-2], data[:, -1:], test_size=0.2, random_state=123)\n",
    "\n",
    "inp_data_test, inp_data_valid, out_data_test, out_data_valid = train_test_split(\n",
    "    inp_data_test, out_data_test, test_size=0.5, random_state=123)\n",
    "\n",
    "inp_data_test , out_data_test  = \\\n",
    "    torch.from_numpy(inp_data_test.astype(np.float32)) , torch.from_numpy(out_data_test.astype(np.float32))\n",
    "\n",
    "inp_data_train, out_data_train = \\\n",
    "    torch.from_numpy(inp_data_train.astype(np.float32)), torch.from_numpy(out_data_train.astype(np.float32))\n",
    "\n",
    "inp_data_valid, out_data_valid = \\\n",
    "    torch.from_numpy(inp_data_valid.astype(np.float32)), torch.from_numpy(out_data_valid.astype(np.float32))\n",
    "\n",
    "train_dataset = TensorDataset(inp_data_train, out_data_train)\n",
    "valid_dataset = TensorDataset(inp_data_valid, out_data_valid)\n",
    "test_dataset  = TensorDataset(inp_data_test , out_data_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rqNhIWehf0Wv",
   "metadata": {
    "id": "rqNhIWehf0Wv"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset , batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ba18719",
   "metadata": {
    "id": "6ba18719"
   },
   "outputs": [],
   "source": [
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vorono = nn.Sequential(\n",
    "            nn.Linear(125, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \n",
    "        def inner_init_weights(layer):\n",
    "            if not isinstance(layer, nn.Linear):\n",
    "                return\n",
    "            \n",
    "            nn.init.xavier_uniform_(layer.weight.data)\n",
    "            nn.init.constant_(layer.bias.data, 0.1)\n",
    "            \n",
    "        self.vorono.apply(inner_init_weights)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vorono(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "988d1416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (vorono): Sequential(\n",
       "    (0): Linear(in_features=125, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (8): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassifierModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2821b53b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2821b53b",
    "outputId": "48e55aba-3cb4-4232-cfdc-01b8e12bad40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 10800, 'val': 1350}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders_dict = {'train': train_loader, 'val': valid_loader}\n",
    "dataset_sizes_dict = {'train': len(train_dataset), 'val': len(valid_dataset)}\n",
    "\n",
    "dataset_sizes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "415e3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW, Adam, SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "num_epochs = 10\n",
    "total_step_train = len(train_loader)\n",
    "total_step_validation = len(valid_loader)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "def model_train(model, loader, f_loss, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = f_loss(outputs, targets.squeeze(1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def model_test(model, loader, f_loss):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        N = 0\n",
    "        tot_loss, correct = 0.0, 0.0\n",
    "        for i, (inputs, targets) in enumerate(loader):\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            N += inputs.shape[0]\n",
    "            tot_loss += inputs.shape[0] * f_loss(outputs, targets.squeeze(1)).item()\n",
    "\n",
    "            predicted_targets = outputs.argmax(dim=1)\n",
    "            correct += (predicted_targets == targets).sum().item()\n",
    "            f1 = f1_score(targets, predicted_targets, average='micro')\n",
    "            \n",
    "        return tot_loss/N, correct/N, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd4a1bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     val_loss, val_acc, val_f1 \u001b[38;5;241m=\u001b[39m model_test(model, valid_loader, criterion)\n\u001b[0;32m     10\u001b[0m     train_loss, train_acc, train_f1 \u001b[38;5;241m=\u001b[39m model_test(model, train_loader, criterion)\n",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(model, loader, f_loss, optimizer)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m     17\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m---> 18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mf_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     21\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "for t in range(epochs):\n",
    "    print(\"epoch {}\".format(t + 1))\n",
    "    model_train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc, val_f1 = model_test(model, valid_loader, criterion)\n",
    "    train_loss, train_acc, train_f1 = model_test(model, train_loader, criterion)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    print(\" Training loss: {:.4f}, Training accuracy: {:.4f}, Training f1-score: {:.4f}\".format(train_loss, train_acc, val_f1))\n",
    "    print(\" Validation loss: {:.4f}, Validation accuracy: {:.4f}, Validation f1-score: {:.4f}\".format(val_loss, val_acc, train_f1))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
