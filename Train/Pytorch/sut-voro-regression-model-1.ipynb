{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>type</th>\n",
       "      <th>1-neighbour type</th>\n",
       "      <th>1-neighbour x</th>\n",
       "      <th>1-neighbour y</th>\n",
       "      <th>1-neighbour z</th>\n",
       "      <th>2-neighbour type</th>\n",
       "      <th>2-neighbour x</th>\n",
       "      <th>...</th>\n",
       "      <th>4-faced</th>\n",
       "      <th>5-faced</th>\n",
       "      <th>6-faced</th>\n",
       "      <th>7-faced</th>\n",
       "      <th>8-faced</th>\n",
       "      <th>9-faced</th>\n",
       "      <th>10-faced</th>\n",
       "      <th>11-faced</th>\n",
       "      <th>12-faced</th>\n",
       "      <th>13-faced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0291</td>\n",
       "      <td>54.92020</td>\n",
       "      <td>24.45400</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>26.7424</td>\n",
       "      <td>53.88120</td>\n",
       "      <td>22.42570</td>\n",
       "      <td>1.60</td>\n",
       "      <td>23.7794</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.4982</td>\n",
       "      <td>36.78260</td>\n",
       "      <td>37.07070</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>44.2310</td>\n",
       "      <td>38.35390</td>\n",
       "      <td>35.84600</td>\n",
       "      <td>1.28</td>\n",
       "      <td>40.5901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.3755</td>\n",
       "      <td>24.90850</td>\n",
       "      <td>17.91550</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>43.8712</td>\n",
       "      <td>22.74440</td>\n",
       "      <td>16.34050</td>\n",
       "      <td>1.28</td>\n",
       "      <td>41.8245</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.9179</td>\n",
       "      <td>13.26660</td>\n",
       "      <td>54.69820</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51.7705</td>\n",
       "      <td>14.43000</td>\n",
       "      <td>53.93900</td>\n",
       "      <td>1.28</td>\n",
       "      <td>52.5371</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.7815</td>\n",
       "      <td>28.60990</td>\n",
       "      <td>25.90210</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>31.8357</td>\n",
       "      <td>30.59160</td>\n",
       "      <td>25.31700</td>\n",
       "      <td>1.28</td>\n",
       "      <td>28.2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>26.5783</td>\n",
       "      <td>7.06695</td>\n",
       "      <td>20.12560</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>28.5276</td>\n",
       "      <td>8.42626</td>\n",
       "      <td>20.08580</td>\n",
       "      <td>1.28</td>\n",
       "      <td>24.2580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>54.6684</td>\n",
       "      <td>48.03910</td>\n",
       "      <td>53.69850</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>53.4106</td>\n",
       "      <td>49.75090</td>\n",
       "      <td>52.50440</td>\n",
       "      <td>1.28</td>\n",
       "      <td>54.4029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>35.8328</td>\n",
       "      <td>47.42480</td>\n",
       "      <td>6.19108</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>35.0159</td>\n",
       "      <td>46.58650</td>\n",
       "      <td>3.81853</td>\n",
       "      <td>1.28</td>\n",
       "      <td>33.2776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>15.7849</td>\n",
       "      <td>50.60780</td>\n",
       "      <td>10.77430</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>15.7732</td>\n",
       "      <td>52.02770</td>\n",
       "      <td>12.91640</td>\n",
       "      <td>1.28</td>\n",
       "      <td>15.9683</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>32.0481</td>\n",
       "      <td>42.34380</td>\n",
       "      <td>38.68910</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.28</td>\n",
       "      <td>32.3959</td>\n",
       "      <td>41.92100</td>\n",
       "      <td>36.03680</td>\n",
       "      <td>1.28</td>\n",
       "      <td>32.5525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13500 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x         y         z  type  1-neighbour type  1-neighbour x  \\\n",
       "0      26.0291  54.92020  24.45400  1.28              1.28        26.7424   \n",
       "1      42.4982  36.78260  37.07070  1.60              1.28        44.2310   \n",
       "2      44.3755  24.90850  17.91550  1.60              1.28        43.8712   \n",
       "3      53.9179  13.26660  54.69820  1.28              1.28        51.7705   \n",
       "4      30.7815  28.60990  25.90210  1.28              1.28        31.8357   \n",
       "...        ...       ...       ...   ...               ...            ...   \n",
       "13495  26.5783   7.06695  20.12560  1.28              1.28        28.5276   \n",
       "13496  54.6684  48.03910  53.69850  1.28              1.28        53.4106   \n",
       "13497  35.8328  47.42480   6.19108  1.60              1.28        35.0159   \n",
       "13498  15.7849  50.60780  10.77430  1.28              1.28        15.7732   \n",
       "13499  32.0481  42.34380  38.68910  1.60              1.28        32.3959   \n",
       "\n",
       "       1-neighbour y  1-neighbour z  2-neighbour type  2-neighbour x  ...  \\\n",
       "0           53.88120       22.42570              1.60        23.7794  ...   \n",
       "1           38.35390       35.84600              1.28        40.5901  ...   \n",
       "2           22.74440       16.34050              1.28        41.8245  ...   \n",
       "3           14.43000       53.93900              1.28        52.5371  ...   \n",
       "4           30.59160       25.31700              1.28        28.2009  ...   \n",
       "...              ...            ...               ...            ...  ...   \n",
       "13495        8.42626       20.08580              1.28        24.2580  ...   \n",
       "13496       49.75090       52.50440              1.28        54.4029  ...   \n",
       "13497       46.58650        3.81853              1.28        33.2776  ...   \n",
       "13498       52.02770       12.91640              1.28        15.9683  ...   \n",
       "13499       41.92100       36.03680              1.28        32.5525  ...   \n",
       "\n",
       "       4-faced  5-faced  6-faced  7-faced  8-faced  9-faced  10-faced  \\\n",
       "0          1.0      3.0      4.0      4.0      1.0      0.0       0.0   \n",
       "1          0.0      1.0     10.0      4.0      0.0      0.0       0.0   \n",
       "2          1.0      1.0      9.0      4.0      2.0      0.0       0.0   \n",
       "3          1.0      3.0      3.0      3.0      0.0      0.0       0.0   \n",
       "4          0.0      0.0     12.0      0.0      0.0      0.0       0.0   \n",
       "...        ...      ...      ...      ...      ...      ...       ...   \n",
       "13495      0.0      0.0     12.0      0.0      0.0      0.0       0.0   \n",
       "13496      0.0      5.0      2.0      3.0      0.0      0.0       0.0   \n",
       "13497      0.0      2.0      8.0      6.0      0.0      0.0       0.0   \n",
       "13498      2.0      2.0      4.0      5.0      0.0      1.0       0.0   \n",
       "13499      0.0      2.0      9.0      3.0      1.0      0.0       0.0   \n",
       "\n",
       "       11-faced  12-faced  13-faced  \n",
       "0           0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0  \n",
       "...         ...       ...       ...  \n",
       "13495       0.0       0.0       0.0  \n",
       "13496       0.0       0.0       0.0  \n",
       "13497       0.0       0.0       0.0  \n",
       "13498       0.0       0.0       0.0  \n",
       "13499       0.0       0.0       0.0  \n",
       "\n",
       "[13500 rows x 98 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../Output/output_1.csv')\n",
    "df.drop(columns=[x for x in df.columns if 'id' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()\n",
    "data = data.astype(np.float32)\n",
    "\n",
    "inp_data_train, inp_data_test, out_data_train, out_data_test = train_test_split(\n",
    "    data[:, :-14], data[:, -14:], test_size=0.2, random_state=42)\n",
    "\n",
    "inp_data_train, out_data_train = \\\n",
    "    torch.from_numpy(inp_data_train), torch.from_numpy(out_data_train)\n",
    "inp_data_test, out_data_test = \\\n",
    "    torch.from_numpy(inp_data_test), torch.from_numpy(out_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(inp_data_train, out_data_train)\n",
    "test_dataset = TensorDataset(inp_data_test, out_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nf\n",
    "\n",
    "class RegressionMultiout(nn.Module):\n",
    "    def __init__(self, inputs_size, hidden_size, output_size):\n",
    "        super(RegressionMultiout, self).__init__()\n",
    "        \n",
    "        self.vorono = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(inputs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \n",
    "        def inner_init_weights(layer):\n",
    "            if not isinstance(layer, nn.Linear):\n",
    "                return\n",
    "            \n",
    "            nn.init.xavier_uniform_(layer.weight.data)\n",
    "            nn.init.constant_(layer.bias.data, 0.1)\n",
    "            \n",
    "        self.vorono.apply(inner_init_weights)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vorono(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE = inp_data_train.shape[1], 20, out_data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionMultiout(\n",
       "  (vorono): Sequential(\n",
       "    (0): Dropout(p=0.1, inplace=False)\n",
       "    (1): Linear(in_features=105, out_features=20, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=20, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionMultiout(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1_000\n",
    "batch_size = len(train_loader)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010.learning_rate: 0.00174\n",
      "010.running_loss: 1.24099\n",
      "020.learning_rate: 0.00174\n",
      "020.running_loss: 1.24099\n",
      "030.learning_rate: 0.00174\n",
      "030.running_loss: 1.24099\n",
      "040.learning_rate: 0.00174\n",
      "040.running_loss: 1.24099\n",
      "050.learning_rate: 0.00174\n",
      "050.running_loss: 1.24099\n",
      "060.learning_rate: 0.00174\n",
      "060.running_loss: 1.24099\n",
      "070.learning_rate: 0.00174\n",
      "070.running_loss: 1.24099\n",
      "080.learning_rate: 0.00174\n",
      "080.running_loss: 1.24098\n",
      "090.learning_rate: 0.00174\n",
      "090.running_loss: 1.24098\n",
      "100.learning_rate: 0.00157\n",
      "100.running_loss: 1.24098\n",
      "110.learning_rate: 0.00157\n",
      "110.running_loss: 1.24096\n",
      "120.learning_rate: 0.00157\n",
      "120.running_loss: 1.24096\n",
      "130.learning_rate: 0.00157\n",
      "130.running_loss: 1.24096\n",
      "140.learning_rate: 0.00157\n",
      "140.running_loss: 1.24096\n",
      "150.learning_rate: 0.00157\n",
      "150.running_loss: 1.24096\n",
      "160.learning_rate: 0.00157\n",
      "160.running_loss: 1.24095\n",
      "170.learning_rate: 0.00157\n",
      "170.running_loss: 1.24095\n",
      "180.learning_rate: 0.00157\n",
      "180.running_loss: 1.24095\n",
      "190.learning_rate: 0.00157\n",
      "190.running_loss: 1.24095\n",
      "200.learning_rate: 0.00141\n",
      "200.running_loss: 1.24095\n",
      "210.learning_rate: 0.00141\n",
      "210.running_loss: 1.24093\n",
      "220.learning_rate: 0.00141\n",
      "220.running_loss: 1.24093\n",
      "230.learning_rate: 0.00141\n",
      "230.running_loss: 1.24093\n",
      "240.learning_rate: 0.00141\n",
      "240.running_loss: 1.24093\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      8\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inp, out \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     12\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m model(inp)\n\u001b[0;32m     13\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(prediction, out)\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\code\\sutvoro\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    139\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    140\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = []\n",
    "outputs = {}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    for inp, out in train_loader:\n",
    "        \n",
    "        prediction = model(inp)\n",
    "        loss = criterion(prediction, out)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    running_loss /= batch_size\n",
    "    train_loss.append(running_loss)\n",
    "    outputs[epoch] = {'img':inp, 'out':prediction}\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('%03d.learning_rate: %.05f' % (epoch, optimizer.param_groups[0][\"lr\"]))\n",
    "        print('%03d.running_loss: %.05f' % (epoch, running_loss))\n",
    "    \n",
    "plt.plot(range(1, num_epochs - 9), train_loss[10:])\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Training Loss...')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(inp_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : [13.  0. -0.  0.  0.  2.  7.  3.  0.  0.  0.  0. -0.  0.]\n",
      "Real output: [13.  0.  0.  0.  2.  2.  4.  3.  2.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, predictions.shape[0])\n",
    "print('Prediction :', np.round(predictions[idx].detach().numpy(), 0))\n",
    "print('Real output:', out_data_test[idx].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(inp_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : [13.  0. -0.  0.  0.  2.  7.  3.  0.  0.  0.  0. -0.  0.]\n",
      "Real output: [13.  0.  0.  0.  0.  1. 10.  2.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, predictions.shape[0])\n",
    "print('Prediction :', np.round(predictions[idx].detach().numpy(), 0))\n",
    "print('Real output:', out_data_train[idx].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
